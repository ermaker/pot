version: '3.6'
services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch-oss:${VERSION-6.4.0}
    environment:
      # - discovery.type=single-node
      - bootstrap.memory_lock=true
      - indices.fielddata.cache.size=20%
      # - 'ES_JAVA_OPTS=-Xms256m -Xmx256m -Des.scripting.exception_for_missing_value=true'
      - 'ES_JAVA_OPTS=-Xms512m -Xmx512m -Des.scripting.exception_for_missing_value=true'
    volumes:
      - elasticsearch:/usr/share/elasticsearch/data
    ulimits:
      memlock: -1
    ports:
      - '9200:9200'
      - 9300
    restart: always
    deploy:
      resources:
        limits:
          # memory: 512m
          memory: 1g
  kibana:
    image: docker.elastic.co/kibana/kibana-oss:${VERSION-6.4.0}
    environment:
      - NODE_OPTIONS=--max-old-space-size=200
    labels:
      parse.flow: json.kibana
    ports:
      - '5601:5601'
    restart: always
    deploy:
      resources:
        limits:
          memory: 200m
  fluentd:
    image: ermaker/fluentd
    environment:
      - LOGSPOUT=ignore
      - RUBY_GC_HEAP_OLDOBJECT_LIMIT_FACTOR=0.9
    ports:
      - '5160:5160/udp'
    restart: always
    deploy:
      resources:
        limits:
          cpus: '0.40'
          # memory: 16m
          memory: 80m
    volumes: # TODO
      - ./fluentd/fluent.conf:/fluentd/etc/fluent.conf:ro
      - buffer:/fluentd/log
  logspout:
    image: gliderlabs/logspout
    command: raw://localhost:5160
    environment:
      - 'RAW_FORMAT={"@timestamp":{{ toJSON .Time }},"message":{{ toJSON .Data }},"tag":{{ toJSON ( index .Container.Config.Labels "parse.flow" ) }},"docker":{"hostname":{{ toJSON .Container.Config.Hostname }},"project":{{ toJSON ( index .Container.Config.Labels "com.docker.compose.project" ) }},"service":{{ toJSON ( or ( index .Container.Config.Labels "com.docker.compose.service" ) .Container.Name ) }},"number":{{ toJSON ( index .Container.Config.Labels "com.docker.compose.container-number" ) }},"id":{{ toJSON .Container.ID }}}}'
      - PORT=4226
    volumes:
      # - /etc/hostname:/etc/host_hostname:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
    network_mode: host
    restart: always
    deploy:
      mode: global
      resources:
        limits:
          cpus: '0.20'
          memory: 16m
  metricbeat:
    image: docker.elastic.co/beats/metricbeat-oss:${VERSION-6.4.0}
    command: -e --system.hostfs=/hostfs --strict.perms=false
    user: root
    environment:
      - ES_HOSTS=localhost:9200
      - KIBANA_HOST=localhost:5601
    volumes:
      - /proc:/hostfs/proc:ro
      - /sys/fs/cgroup:/hostfs/sys/fs/cgroup:ro
      - /:/hostfs:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - ./metricbeat/metricbeat.yml:/usr/share/metricbeat/metricbeat.yml:ro
      - ./metricbeat/modules.d:/usr/share/metricbeat/modules.d:ro
    network_mode: host
    restart: always
    deploy:
      mode: global
      resources:
        limits:
          cpus: '0.20'
          memory: 64m

  # logstash:
  #   image: docker.elastic.co/logstash/logstash-oss:${VERSION-6.4.0}
  #   environment:
  #     - 'LS_JAVA_OPTS=-Xms256m -Xmx256m'
  #   ports:
  #     - '4225:4225/udp'
  #     - '5044:5044'
  #     - '9600:9600'
  #   restart: always
  #   deploy:
  #     resources:
  #       limits:
  #         memory: 512m
  #   volumes: # TODO
  #     - ./logstash/logstash.conf:/usr/share/logstash/pipeline/logstash.conf:ro
volumes:
  elasticsearch:
  buffer:
